# Syllabus

This course focuses on advanced deep learning techniques for natural language processing using the NVIDIA NeMo framework and DGX H100 server. It emphasizes the training, optimization, and deployment of Large Language Models (LLMs), including practical application development. Students will gain hands-on LLM development experience through team projects.

## Learning Objectives

1. Master the use of NVIDIA NeMo framework and DGX H100 server.
2. Understand and practice LLM architecture and training methods.
3. Acquire techniques for LLM training and optimization using custom datasets.
4. Learn LLM development methods in distributed learning environments.
5. Develop the ability to implement RAG (Retrieval-Augmented Generation) systems.
6. Cultivate skills to design and develop real-world LLM-based applications.

## Course Outline

Week 1

- Overview: Introduction to NVIDIA NeMo Framework and DGX H100 server
- Key Learning Content: NeMo framework structure, DGX H100 server usage, team project introduction
- Note: Lecture, Practice (NeMo installation and basic usage), Team formation

Week 2

- Overview: LLM basics using NeMo
- Key Learning Content: Understanding LLM architecture, exploring NeMo's LLM models
- Note: Lecture, Practice (Simple LLM experiments using NeMo)

Week 3

- Overview: LLM training techniques I
- Key Learning Content: Pre-training strategies, LLM training setup in NeMo
- Note: Lecture, Practice (Small-scale LLM training using NeMo)

Week 4

- Overview: LLM training techniques II
- Key Learning Content: Continuous learning, fine-tuning strategies
- Note: Lecture, Practice (LLM fine-tuning using NeMo), Team project planning

Week 5

- Overview: NeMo custom dataset implementation I
- Key Learning Content: Data preprocessing, text data cleaning
- Note: Lecture, Practice (Custom dataset preprocessing for NeMo)

Week 6

- Overview: NeMo custom dataset implementation II
- Key Learning Content: Custom data loader implementation, data augmentation techniques
- Note: Lecture, Practice (Custom data loader implementation for NeMo), Team project progress

Week 7

- Overview: Distributed learning techniques
- Key Learning Content: Distributed learning setup on DGX H100, parallelization strategies
- Note: Lecture, Practice (Running distributed learning on DGX H100)

Week 8

- Overview: Midterm project presentation and model optimization
- Key Learning Content: Team project midterm presentation, model compression, quantization techniques
- Note: Midterm project presentations, feedback session

Week 9

- Overview: LLM inference optimization
- Key Learning Content: Efficient inference techniques, utilizing NVIDIA TensorRT
- Note: Lecture, Practice (NeMo model inference optimization)

Week 10

- Overview: LLM model deployment
- Key Learning Content: Model serving, utilizing NeMo Inference Microservices
- Note: Lecture, Practice (NeMo model deployment and performance measurement), Team project progress

Week 11

- Overview: RAG (Retrieval-Augmented Generation) implementation I
- Key Learning Content: Understanding RAG architecture, building vector databases
- Note: Lecture, Practice (Basic setup of NeMo Retriever)

Week 12

- Overview: RAG (Retrieval-Augmented Generation) implementation II
- Key Learning Content: Advanced use of NeMo Retriever, building RAG pipelines
- Note: Lecture, Practice (Implementing RAG system using NeMo), Team project progress

Week 13

- Overview: LLM application development I
- Key Learning Content: Utilizing NeMo Guardrails, application design
- Note: Lecture, Practice (Designing LLM applications based on NeMo)

Week 14

- Overview: LLM application development II
- Key Learning Content: User interface implementation, application testing and debugging
- Note: Lecture, Practice (Implementing LLM applications based on NeMo), Finalizing team projects

Week 15

- Overview: Final project presentation and course wrap-up
- Key Learning Content: Team project result presentations, review of LLM development pipeline
- Note: Team project presentations, peer evaluation, comprehensive discussion

## Evaluation

1. Attendance and Participation (10%)
   - Evaluation method: Weekly attendance check and in-class participation
   - Evaluation timing: Every week
2. Weekly Practical Assignments (20%)
   - Evaluation method: Submission of weekly practice results
   - Evaluation timing: Weeks 2-7, 9-14
3. Midterm Project Presentation (20%)
   - Evaluation method: Team project interim results and presentation
   - Evaluation timing: Week 8
4. Final Project (50%)
   - Evaluation method: LLM application development results, technical documentation, presentation, peer evaluation
   - Evaluation timing: Week 15

## Course Materials

- Lecture Note: [https://deepnlp2024.halla.ai](https://deepnlp2024.halla.ai)
- GitHub: [https://github.com/entelecheia/deepnlp-2024](https://github.com/entelecheia/intdeepnlp-2024)
- Main textbook: NVIDIA NeMo official documentation and tutorials
- Additional references: Latest papers on LLMs, NVIDIA technical blog posts, GitHub repositories

## Prerequisites

- Python programming (Intermediate level or above)
- Basics of machine learning and deep learning
- Introduction to natural language processing

## Additional Notes

- DGX H100 server account required, to be issued before the course
- Team projects will be conducted in groups of 3-4 members
- Course content may be partially modified to reflect the latest technology trends

## Weekly Practice Assignment Guidelines

- Weekly assignments due by Friday midnight
- Code management and submission through GitHub recommended

## Project Guidelines

- Midterm project: Fine-tuning and performance improvement of LLM for specific tasks
- Final project: Developing LLM-based applications solving real-world problems
- Project deliverables should include code, technical documentation, and presentation materials
- Open-source contribution or paper writing can be substituted (prior consultation required)
