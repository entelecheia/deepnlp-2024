# Home

[![halla-img]][halla-url]
[![home-img]][home-url]
[![course-img]][course-url]
[![lecture-img]][lecture-url]
[![pypi-image]][pypi-url]
[![release-date-image]][release-url]
[![license-image]][license-url]

<!-- Links: -->

[halla-img]: https://img.shields.io/badge/CHU-halla.ai-blue
[halla-url]: https://halla.ai
[home-img]: https://img.shields.io/badge/home-jeju.ai-blue
[home-url]: https://home.jeju.ai
[home-repo-url]: https://entelecheia.me/repositories
[course-img]: https://img.shields.io/badge/course-jeju.ai-blue
[course-url]: https://course.jeju.ai
[lecture-img]: https://img.shields.io/badge/lecture-jeju.ai-blue
[lecture-url]: https://lecture.jeju.ai
[hyperfast python template]: https://github.com/entelecheia/hyperfast-course-template
[codecov-image]: https://codecov.io/gh/entelecheia/deepnlp-2024/branch/main/graph/badge.svg?token=OMNrbNOBEj
[codecov-url]: https://codecov.io/gh/entelecheia/deepnlp-2024
[pypi-image]: https://img.shields.io/pypi/v/deepnlp-2024
[license-image]: https://img.shields.io/github/license/entelecheia/deepnlp-2024
[license-url]: https://github.com/entelecheia/deepnlp-2024/blob/main/LICENSE
[version-image]: https://img.shields.io/github/v/release/entelecheia/deepnlp-2024?sort=semver
[release-date-image]: https://img.shields.io/github/release-date/entelecheia/deepnlp-2024
[release-url]: https://github.com/entelecheia/deepnlp-2024/releases
[jupyter-book-image]: https://jupyterbook.org/en/stable/_images/badge.svg
[repo-url]: https://github.com/entelecheia/deepnlp-2024
[pypi-url]: https://pypi.org/project/deepnlp-2024
[docs-url]: https://deepnlp2024.jeju.ai
[changelog]: https://github.com/entelecheia/deepnlp-2024/blob/main/CHANGELOG.md
[contributing guidelines]: https://github.com/entelecheia/deepnlp-2024/blob/main/CONTRIBUTING.md

<!-- Links: -->

This course focuses on advanced deep learning techniques for natural language processing using the NVIDIA NeMo framework and DGX H100 server. It emphasizes the training, optimization, and deployment of Large Language Models (LLMs), including practical application development. Students will gain hands-on LLM development experience through team projects.

## Table of Contents

```{tableofcontents}

```

## Learning Objectives

1. Master the use of NVIDIA NeMo framework and DGX H100 server.
2. Understand and practice LLM architecture and training methods.
3. Acquire techniques for LLM training and optimization using custom datasets.
4. Learn LLM development methods in distributed learning environments.
5. Develop the ability to implement RAG (Retrieval-Augmented Generation) systems.
6. Cultivate skills to design and develop real-world LLM-based applications.

## Evaluation

1. Attendance and Participation (10%)
   - Evaluation method: Weekly attendance check and in-class participation
   - Evaluation timing: Every week
2. Weekly Practical Assignments (20%)
   - Evaluation method: Submission of weekly practice results
   - Evaluation timing: Weeks 2-7, 9-14
3. Midterm Project Presentation (20%)
   - Evaluation method: Team project interim results and presentation
   - Evaluation timing: Week 8
4. Final Project (50%)
   - Evaluation method: LLM application development results, technical documentation, presentation, peer evaluation
   - Evaluation timing: Week 15

## Course Materials

- Lecture Note: [https://deepnlp2024.halla.ai](https://deepnlp2024.halla.ai)
- GitHub: [https://github.com/entelecheia/deepnlp-2024](https://github.com/entelecheia/intdeepnlp-2024)
- Main textbook: NVIDIA NeMo official documentation and tutorials
- Additional references: Latest papers on LLMs, NVIDIA technical blog posts, GitHub repositories

## Prerequisites

- Python programming (Intermediate level or above)
- Basics of machine learning and deep learning
- Introduction to natural language processing

## Additional Notes

- DGX H100 server account required, to be issued before the course
- Team projects will be conducted in groups of 3-4 members
- Course content may be partially modified to reflect the latest technology trends

## Weekly Practice Assignment Guidelines

- Weekly assignments due by Friday midnight
- Code management and submission through GitHub recommended

## Project Guidelines

- Midterm project: Fine-tuning and performance improvement of LLM for specific tasks
- Final project: Developing LLM-based applications solving real-world problems
- Project deliverables should include code, technical documentation, and presentation materials
- Open-source contribution or paper writing can be substituted (prior consultation required)

## Changelog

See the [CHANGELOG] for more information.

## Contributing

Contributions are welcome! Please see the [contributing guidelines] for more information.

## License

This project is released under the [CC-BY-4.0 License][license-url].
